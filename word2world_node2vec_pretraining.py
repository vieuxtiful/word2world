"""
Word2World Pre-Training Engine - Node2Vec Module
=================================================

Node2Vec training and A/B testing framework for the Word2World platform.
Enables experimentation with different Node2Vec configurations to optimize
network structure embeddings for bridge identification.

Features:
- Configurable Node2Vec parameters (p, q, walk length, dimensions)
- Bridge-aware edge weighting
- A/B testing framework for comparing configurations
- Multiple graph splitting strategies (random, community-aware)
- Comprehensive evaluation metrics (link prediction, modularity, bridge identification)
- Statistical significance testing

Authors: Shu Bai, Xiaoyue Cao, Jinxing Chen, Yunzhou Dai, Vieux Valcin, Huiyi Zhang
Version: 1.0
Date: October 22, 2025
License: MIT

Installation:
    pip install networkx node2vec numpy scikit-learn scipy

Usage:
    from word2world_node2vec_pretraining import Node2VecEncoderAB, Node2VecExperimentConfig, Node2VecABTest
    
    # Configure experiment arms
    config_a = Node2VecExperimentConfig(
        arm_id="bfs_style",
        p=1.0,
        q=0.5,  # BFS-like exploration
        dimensions=128
    )
    
    config_b = Node2VecExperimentConfig(
        arm_id="dfs_style",
        p=1.0,
        q=2.0,  # DFS-like exploration
        dimensions=128
    )
    
    # Run A/B test
    ab_test = Node2VecABTest(config_a, config_b)
    results = ab_test.run_experiment(social_graph, user_ids, semantic_positions)
    
    print(f"Winner: {results.winning_arm}")
    print(f"Confidence: {results.confidence:.2%}")

Parameters:
    p: Return parameter (controls likelihood of returning to previous node)
    q: In-out parameter (controls exploration vs exploitation)
       - q < 1: BFS-like (local exploration)
       - q > 1: DFS-like (distant exploration)
       - q = 1: Balanced
"""

Word2World Pre-Training Engine (Node2Vec Module).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ndwXLv8sqPHGqrz4Zkk9d2XMEWds-3dz
"""

# -*- coding: utf-8 -*-
"""
Node2Vec A/B Testing Framework for Word2World
==============================================

A/B testing framework for evaluating different Node2Vec configurations
in the Word2World platform. Designed for use in Jupyter Notebooks and Google Colab.

Authors: Shu Bai, Xiaoyue Cao, Jinxing Chen, Yunzhou Dai, Vieux Valcin, Huiyi Zhang
Version: 1.0
Date: October 22, 2025
License: MIT

Usage in Jupyter Notebook:
    # Upload word2world.py to your notebook environment
    from word2world import STAPv4PreprocessingLayer, STAPv4Config
    from node2vec_ab_testing import Node2VecABTest, Node2VecExperimentConfig, run_node2vec_ab_experiment

    # Run experiment
    results = run_node2vec_ab_experiment(social_graph, user_ids, semantic_positions)
"""

import networkx as nx
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
import random
import logging
from scipy import stats
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans

try:
    from node2vec import Node2Vec as Node2VecModel
except ImportError:
    Node2VecModel = None
    print("Warning: node2vec package not installed. Install with: pip install node2vec")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================================
# Configuration
# ============================================================================

@dataclass
class Node2VecExperimentConfig:
    """Configuration for a Node2Vec experimental arm."""
    arm_id: str
    dimensions: int = 128
    walk_length: int = 30
    num_walks: int = 200
    p: float = 1.0  # Return parameter
    q: float = 1.0  # In-out parameter
    window_size: int = 10
    workers: int = 4
    weight_key: Optional[str] = 'weight'

    # Bridge-aware parameters
    use_bridge_weights: bool = True
    bridge_weight_strength: float = 2.0

@dataclass
class ExperimentResults:
    """Container for A/B experiment results."""
    arm_a_metrics: Dict[str, float]
    arm_b_metrics: Dict[str, float]
    statistical_tests: Dict[str, Dict]
    winning_arm: str
    confidence: float
    effect_sizes: Dict[str, float]

# ============================================================================
# Graph Splitting Strategies
# ============================================================================

class GraphSplitStrategy:
    """Base class for graph splitting strategies."""

    def split_graph(self, graph: nx.Graph, split_ratio: float = 0.5) -> Tuple[nx.Graph, nx.Graph]:
        """Split graph into two subgraphs."""
        raise NotImplementedError

class RandomNodeSplit(GraphSplitStrategy):
    """Split graph by randomly assigning nodes to different arms."""

    def split_graph(self, graph: nx.Graph, split_ratio: float = 0.5) -> Tuple[nx.Graph, nx.Graph]:
        nodes = list(graph.nodes())
        random.shuffle(nodes)

        split_idx = int(len(nodes) * split_ratio)
        arm_a_nodes = set(nodes[:split_idx])
        arm_b_nodes = set(nodes[split_idx:])

        # Create subgraphs
        arm_a_graph = graph.subgraph(arm_a_nodes).copy()
        arm_b_graph = graph.subgraph(arm_b_nodes).copy()

        logger.info(f"Random split: Arm A={len(arm_a_nodes)} nodes, Arm B={len(arm_b_nodes)} nodes")
        return arm_a_graph, arm_b_graph

class CommunityAwareSplit(GraphSplitStrategy):
    """Split graph while preserving community structure."""

    def split_graph(self, graph: nx.Graph, split_ratio: float = 0.5) -> Tuple[nx.Graph, nx.Graph]:
        # Detect communities
        try:
            from networkx.algorithms import community
            communities = list(community.greedy_modularity_communities(graph))
        except:
            # Fallback to connected components
            communities = list(nx.connected_components(graph))

        # Split communities between arms
        arm_a_nodes = set()
        arm_b_nodes = set()

        for community_nodes in communities:
            community_list = list(community_nodes)
            random.shuffle(community_list)

            split_idx = int(len(community_list) * split_ratio)
            arm_a_nodes.update(community_list[:split_idx])
            arm_b_nodes.update(community_list[split_idx:])

        # Create subgraphs
        arm_a_graph = graph.subgraph(arm_a_nodes).copy()
        arm_b_graph = graph.subgraph(arm_b_nodes).copy()

        logger.info(f"Community-aware split: Arm A={len(arm_a_nodes)} nodes, Arm B={len(arm_b_nodes)} nodes")
        return arm_a_graph, arm_b_graph

# ============================================================================
# Node2Vec Encoder with A/B Testing Support
# ============================================================================

class Node2VecEncoderAB:
    """
    Node2Vec encoder with A/B testing capabilities.
    """

    def __init__(self, config: Node2VecExperimentConfig):
        """
        Initialize Node2Vec encoder for A/B testing.

        Args:
            config: Experiment configuration
        """
        self.config = config
        self.model = None
        self.embeddings = {}

        if Node2VecModel is None:
            logger.warning("node2vec package not available")

        logger.info(f"Node2Vec encoder initialized for arm: {self.config.arm_id}")

    def train(self, graph: nx.Graph):
        """
        Train Node2Vec model on the graph.

        Args:
            graph: NetworkX graph
        """
        if Node2VecModel is None:
            logger.warning("node2vec package not available")
            return

        if graph.number_of_nodes() < 2:
            logger.warning(f"[{self.config.arm_id}] Insufficient nodes for training")
            return

        logger.info(f"[{self.config.arm_id}] Training Node2Vec on {graph.number_of_nodes()} nodes")

        # Initialize Node2Vec
        node2vec = Node2VecModel(
            graph,
            dimensions=self.config.dimensions,
            walk_length=self.config.walk_length,
            num_walks=self.config.num_walks,
            p=self.config.p,
            q=self.config.q,
            workers=self.config.workers,
            weight_key=self.config.weight_key if self.config.use_bridge_weights else None,
            quiet=True
        )

        # Train model
        self.model = node2vec.fit(
            window=self.config.window_size,
            min_count=1,
            batch_words=4
        )

        # Cache embeddings
        for node in graph.nodes():
            try:
                self.embeddings[node] = self.model.wv[str(node)]
            except KeyError:
                self.embeddings[node] = np.zeros(self.config.dimensions)

        logger.info(f"[{self.config.arm_id}] Training complete: {len(self.embeddings)} embeddings")

    def evaluate(self, graph: nx.Graph) -> Dict[str, float]:
        """
        Evaluate Node2Vec embeddings on various metrics.

        Args:
            graph: NetworkX graph

        Returns:
            Dictionary of evaluation metrics
        """
        if not self.embeddings:
            return {}

        metrics = {}

        # 1. Link prediction accuracy
        metrics['link_prediction_accuracy'] = self._evaluate_link_prediction(graph)

        # 2. Community detection quality
        metrics['modularity'] = self._evaluate_community_detection(graph)

        # 3. Embedding quality
        metrics['embedding_variance'] = self._compute_embedding_variance()
        metrics['embedding_coherence'] = self._compute_embedding_coherence(graph)

        # 4. Bridge identification
        metrics['bridge_identification_score'] = self._evaluate_bridge_identification(graph)

        return metrics

    def _evaluate_link_prediction(self, graph: nx.Graph, test_ratio: float = 0.1) -> float:
        """Evaluate link prediction accuracy."""
        edges = list(graph.edges())
        if len(edges) < 10:
            return 0.0

        # Sample test edges
        n_test = max(1, int(len(edges) * test_ratio))
        test_edges = random.sample(edges, n_test)

        # Generate negative samples
        non_edges = list(nx.non_edges(graph))
        if len(non_edges) < n_test:
            return 0.0
        negative_edges = random.sample(non_edges, n_test)

        # Compute scores
        correct = 0
        for u, v in test_edges:
            if u in self.embeddings and v in self.embeddings:
                pos_score = cosine_similarity(
                    self.embeddings[u].reshape(1, -1),
                    self.embeddings[v].reshape(1, -1)
                )[0, 0]

                # Sample a negative edge
                neg_u, neg_v = random.choice(negative_edges)
                if neg_u in self.embeddings and neg_v in self.embeddings:
                    neg_score = cosine_similarity(
                        self.embeddings[neg_u].reshape(1, -1),
                        self.embeddings[neg_v].reshape(1, -1)
                    )[0, 0]

                    if pos_score > neg_score:
                        correct += 1

        return correct / n_test if n_test > 0 else 0.0

    def _evaluate_community_detection(self, graph: nx.Graph) -> float:
        """Evaluate community detection using modularity."""
        if len(self.embeddings) < 2:
            return 0.0

        # Cluster embeddings
        embedding_matrix = np.array([self.embeddings[node] for node in graph.nodes()
                                    if node in self.embeddings])

        if len(embedding_matrix) < 2:
            return 0.0

        n_clusters = min(5, len(embedding_matrix) // 2)
        if n_clusters < 2:
            return 0.0

        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        labels = kmeans.fit_predict(embedding_matrix)

        # Compute modularity
        node_to_community = {node: labels[i] for i, node in enumerate(graph.nodes())
                            if node in self.embeddings}

        modularity = 0.0
        m = graph.number_of_edges()
        if m == 0:
            return 0.0

        for u, v in graph.edges():
            if u in node_to_community and v in node_to_community:
                if node_to_community[u] == node_to_community[v]:
                    k_u = graph.degree(u)
                    k_v = graph.degree(v)
                    modularity += 1 - (k_u * k_v) / (2 * m)

        modularity /= (2 * m)
        return modularity

    def _compute_embedding_variance(self) -> float:
        """Compute variance of embeddings."""
        if not self.embeddings:
            return 0.0

        embedding_matrix = np.array(list(self.embeddings.values()))
        return np.var(embedding_matrix)

    def _compute_embedding_coherence(self, graph: nx.Graph) -> float:
        """Compute coherence of embeddings for connected nodes."""
        if not self.embeddings:
            return 0.0

        coherence_scores = []
        for u, v in graph.edges():
            if u in self.embeddings and v in self.embeddings:
                similarity = cosine_similarity(
                    self.embeddings[u].reshape(1, -1),
                    self.embeddings[v].reshape(1, -1)
                )[0, 0]
                coherence_scores.append(similarity)

        return np.mean(coherence_scores) if coherence_scores else 0.0

    def _evaluate_bridge_identification(self, graph: nx.Graph) -> float:
        """Evaluate ability to identify bridge nodes."""
        if not self.embeddings:
            return 0.0

        # Compute betweenness centrality as ground truth for bridges
        betweenness = nx.betweenness_centrality(graph)

        # Compute embedding-based bridge scores
        bridge_scores = {}
        for node in graph.nodes():
            if node not in self.embeddings:
                continue

            # Bridge score: average distance to neighbors
            neighbors = list(graph.neighbors(node))
            if not neighbors:
                bridge_scores[node] = 0.0
                continue

            distances = []
            for neighbor in neighbors:
                if neighbor in self.embeddings:
                    dist = np.linalg.norm(self.embeddings[node] - self.embeddings[neighbor])
                    distances.append(dist)

            bridge_scores[node] = np.mean(distances) if distances else 0.0

        # Compute correlation between betweenness and bridge scores
        if len(bridge_scores) < 2:
            return 0.0

        common_nodes = set(betweenness.keys()) & set(bridge_scores.keys())
        if len(common_nodes) < 2:
            return 0.0

        betweenness_vals = [betweenness[node] for node in common_nodes]
        bridge_vals = [bridge_scores[node] for node in common_nodes]

        correlation, _ = stats.pearsonr(betweenness_vals, bridge_vals)
        return abs(correlation)

# ============================================================================
# A/B Testing Framework
# ============================================================================

class Node2VecABTest:
    """
    A/B testing framework for comparing Node2Vec configurations.
    """

    def __init__(self, arm_a_config: Node2VecExperimentConfig,
                 arm_b_config: Node2VecExperimentConfig,
                 split_strategy: Optional[GraphSplitStrategy] = None):
        """
        Initialize A/B test with two experimental arms.

        Args:
            arm_a_config: Configuration for arm A
            arm_b_config: Configuration for arm B
            split_strategy: Strategy for splitting graph (default: RandomNodeSplit)
        """
        self.arm_a_config = arm_a_config
        self.arm_b_config = arm_b_config
        self.split_strategy = split_strategy or RandomNodeSplit()

        self.arm_a_encoder = Node2VecEncoderAB(arm_a_config)
        self.arm_b_encoder = Node2VecEncoderAB(arm_b_config)

        self.results = None
        self.user_assignments = {}

        logger.info(f"Node2Vec A/B Test initialized: {arm_a_config.arm_id} vs {arm_b_config.arm_id}")

    def prepare_experiment_graph(self, social_graph: nx.Graph,
                                semantic_positions: Optional[Dict[str, np.ndarray]] = None) -> nx.Graph:
        """
        Prepare graph with bridge-aware edge weighting.

        Args:
            social_graph: Raw social connection graph
            semantic_positions: Optional semantic coordinates for bridge weighting

        Returns:
            Prepared graph with bridge-aware weights
        """
        prepared_graph = social_graph.copy()

        # Add bridge-aware weights if semantic positions available
        if semantic_positions:
            for u, v, data in prepared_graph.edges(data=True):
                bridge_weight = self._compute_bridge_weight(u, v, semantic_positions)
                data['weight'] = bridge_weight
                data['bridge_score'] = bridge_weight - 1.0
        else:
            # Default uniform weights
            for u, v, data in prepared_graph.edges(data=True):
                data['weight'] = 1.0
                data['bridge_score'] = 0.0

        logger.info(f"Experiment graph prepared: {prepared_graph.number_of_nodes()} nodes, "
                   f"{prepared_graph.number_of_edges()} edges")
        return prepared_graph

    def _compute_bridge_weight(self, user1: str, user2: str,
                              semantic_positions: Dict[str, np.ndarray]) -> float:
        """Compute bridge-aware edge weight based on semantic distance."""
        if user1 not in semantic_positions or user2 not in semantic_positions:
            return 1.0

        pos1 = semantic_positions[user1]
        pos2 = semantic_positions[user2]

        # Semantic distance (normalized)
        distance = np.linalg.norm(pos1 - pos2)

        # Bridge score: higher for medium distances (optimal bridge range [0.3, 0.5])
        bridge_score = np.exp(-((distance - 0.4) ** 2) / 0.1)

        # Apply bridge weight strength
        weight = 1.0 + bridge_score

        return float(weight)

    def run_experiment(self, experiment_graph: nx.Graph,
                      user_ids: List[str],
                      split_ratio: float = 0.5) -> ExperimentResults:
        """
        Run the complete Node2Vec A/B experiment.

        Args:
            experiment_graph: Prepared graph with bridge-aware weights
            user_ids: List of user IDs to include in experiment
            split_ratio: Ratio for splitting users between arms

        Returns:
            Comprehensive experiment results
        """
        logger.info("Starting Node2Vec A/B experiment...")

        # Step 1: Split users into experimental arms
        arm_a_graph, arm_b_graph = self._assign_users_to_arms(experiment_graph, user_ids, split_ratio)

        # Step 2: Train Node2Vec models for each arm
        self.arm_a_encoder.train(arm_a_graph)
        self.arm_b_encoder.train(arm_b_graph)

        # Step 3: Evaluate both arms
        arm_a_metrics = self.arm_a_encoder.evaluate(arm_a_graph)
        arm_b_metrics = self.arm_b_encoder.evaluate(arm_b_graph)

        # Step 4: Statistical analysis
        statistical_tests, effect_sizes = self._perform_statistical_analysis(arm_a_metrics, arm_b_metrics)

        # Step 5: Determine winning arm
        winning_arm, confidence = self._select_winning_arm(arm_a_metrics, arm_b_metrics, statistical_tests)

        # Store results
        self.results = ExperimentResults(
            arm_a_metrics=arm_a_metrics,
            arm_b_metrics=arm_b_metrics,
            statistical_tests=statistical_tests,
            winning_arm=winning_arm,
            confidence=confidence,
            effect_sizes=effect_sizes
        )

        logger.info(f"Experiment completed. Winner: {winning_arm} (confidence: {confidence:.3f})")
        return self.results

    def _assign_users_to_arms(self, graph: nx.Graph, user_ids: List[str],
                             split_ratio: float) -> Tuple[nx.Graph, nx.Graph]:
        """Assign users to experimental arms."""
        # Filter graph to only include experiment users
        experiment_users = set(user_ids)
        filtered_graph = graph.subgraph(experiment_users).copy()

        # Split graph using the specified strategy
        arm_a_graph, arm_b_graph = self.split_strategy.split_graph(filtered_graph, split_ratio)

        # Record user assignments
        for user_id in arm_a_graph.nodes():
            self.user_assignments[user_id] = self.arm_a_config.arm_id
        for user_id in arm_b_graph.nodes():
            self.user_assignments[user_id] = self.arm_b_config.arm_id

        logger.info(f"User assignments: {self.arm_a_config.arm_id}={arm_a_graph.number_of_nodes()}, "
                   f"{self.arm_b_config.arm_id}={arm_b_graph.number_of_nodes()}")

        return arm_a_graph, arm_b_graph

    def _perform_statistical_analysis(self, arm_a_metrics: Dict,
                                     arm_b_metrics: Dict) -> Tuple[Dict, Dict]:
        """Perform statistical significance tests."""
        tests = {}
        effect_sizes = {}

        for metric_name in arm_a_metrics.keys():
            a_val = arm_a_metrics[metric_name]
            b_val = arm_b_metrics[metric_name]

            # Compute difference and effect size
            diff = a_val - b_val
            pooled_std = np.sqrt((a_val ** 2 + b_val ** 2) / 2)
            effect_size = diff / pooled_std if pooled_std > 0 else 0.0

            # Relative difference
            relative_diff = abs(diff) / max(abs(a_val), abs(b_val), 1e-10)

            tests[metric_name] = {
                'arm_a_value': a_val,
                'arm_b_value': b_val,
                'difference': diff,
                'relative_difference': relative_diff,
                'significant': relative_diff > 0.05  # 5% threshold
            }

            effect_sizes[metric_name] = effect_size

        return tests, effect_sizes

    def _select_winning_arm(self, arm_a_metrics: Dict, arm_b_metrics: Dict,
                          statistical_tests: Dict) -> Tuple[str, float]:
        """Select winning arm based on metrics."""
        # Primary metrics for Node2Vec
        primary_metrics = ['link_prediction_accuracy', 'bridge_identification_score', 'modularity']

        scores = {'arm_a': 0, 'arm_b': 0}

        for metric in primary_metrics:
            if metric in arm_a_metrics and metric in arm_b_metrics:
                if arm_a_metrics[metric] > arm_b_metrics[metric]:
                    scores['arm_a'] += 1
                else:
                    scores['arm_b'] += 1

        if scores['arm_a'] > scores['arm_b']:
            winning_arm = self.arm_a_config.arm_id
            confidence = scores['arm_a'] / len(primary_metrics)
        else:
            winning_arm = self.arm_b_config.arm_id
            confidence = scores['arm_b'] / len(primary_metrics)

        return winning_arm, confidence

    def get_user_embedding(self, user_id: str) -> Optional[np.ndarray]:
        """Get embedding for a user based on their arm assignment."""
        if user_id in self.user_assignments:
            arm = self.user_assignments[user_id]
            if arm == self.arm_a_config.arm_id:
                return self.arm_a_encoder.get_embedding(user_id)
            else:
                return self.arm_b_encoder.get_embedding(user_id)
        return None

    def generate_report(self) -> str:
        """Generate comprehensive experiment report."""
        if self.results is None:
            return "No experiment results available."

        report = []
        report.append("=" * 80)
        report.append("NODE2VEC A/B EXPERIMENT REPORT")
        report.append("=" * 80)

        # Configuration summary
        report.append("\nEXPERIMENT CONFIGURATION:")
        report.append("-" * 40)
        report.append(f"Arm A: {self.arm_a_config.arm_id}")
        report.append(f"  Dimensions: {self.arm_a_config.dimensions}")
        report.append(f"  p: {self.arm_a_config.p}, q: {self.arm_a_config.q}")
        report.append(f"  Bridge Weights: {self.arm_a_config.use_bridge_weights}")
        report.append(f"\nArm B: {self.arm_b_config.arm_id}")
        report.append(f"  Dimensions: {self.arm_b_config.dimensions}")
        report.append(f"  p: {self.arm_b_config.p}, q: {self.arm_b_config.q}")
        report.append(f"  Bridge Weights: {self.arm_b_config.use_bridge_weights}")

        # Results summary
        report.append("\nEXPERIMENT RESULTS:")
        report.append("-" * 40)
        report.append(f"Winning Arm: {self.results.winning_arm}")
        report.append(f"Confidence: {self.results.confidence:.3f}")

        # Metrics comparison
        report.append("\nMETRICS COMPARISON:")
        report.append("-" * 40)
        for metric_name in self.results.arm_a_metrics.keys():
            a_val = self.results.arm_a_metrics[metric_name]
            b_val = self.results.arm_b_metrics[metric_name]
            diff = a_val - b_val
            sig_info = self.results.statistical_tests.get(metric_name, {})
            significant = sig_info.get('significant', False)
            effect_size = self.results.effect_sizes.get(metric_name, 0.0)

            sig_marker = "***" if significant else ""
            report.append(f"{metric_name}:")
            report.append(f"  Arm A: {a_val:.4f}")
            report.append(f"  Arm B: {b_val:.4f}")
            report.append(f"  Difference: {diff:+.4f} {sig_marker}")
            report.append(f"  Effect Size: {effect_size:.4f}")

        # Recommendations
        report.append("\nRECOMMENDATIONS:")
        report.append("-" * 40)
        if self.results.confidence > 0.7:
            report.append(f"âœ… STRONG EVIDENCE: Deploy {self.results.winning_arm} configuration")
        elif self.results.confidence > 0.5:
            report.append(f"ðŸ“Š MODERATE EVIDENCE: Consider {self.results.winning_arm} configuration")
        else:
            report.append("ðŸ” INCONCLUSIVE: Continue experimentation or refine configurations")

        return "\n".join(report)

# ============================================================================
# Pre-defined Configurations
# ============================================================================

def get_baseline_vs_bridge_aware_configs() -> Tuple[Node2VecExperimentConfig, Node2VecExperimentConfig]:
    """Get configurations for baseline vs bridge-aware experiment."""
    baseline_config = Node2VecExperimentConfig(
        arm_id="baseline",
        dimensions=128,
        walk_length=30,
        num_walks=200,
        p=1.0,
        q=1.0,
        use_bridge_weights=False
    )

    bridge_aware_config = Node2VecExperimentConfig(
        arm_id="bridge_aware",
        dimensions=128,
        walk_length=30,
        num_walks=200,
        p=0.8,  # Encourage local exploration
        q=0.5,  # Bias toward bridge nodes
        use_bridge_weights=True,
        bridge_weight_strength=2.0
    )

    return baseline_config, bridge_aware_config

# ============================================================================
# Quick Start Function
# ============================================================================

def run_node2vec_ab_experiment(
    social_graph: nx.Graph,
    user_ids: List[str],
    semantic_positions: Optional[Dict[str, np.ndarray]] = None,
    arm_a_config: Optional[Node2VecExperimentConfig] = None,
    arm_b_config: Optional[Node2VecExperimentConfig] = None,
    split_strategy: Optional[GraphSplitStrategy] = None
) -> ExperimentResults:
    """
    Quick start function to run Node2Vec A/B experiment.

    Args:
        social_graph: NetworkX graph of social connections
        user_ids: List of user IDs to include in experiment
        semantic_positions: Optional semantic coordinates for bridge weighting
        arm_a_config: Optional configuration for arm A
        arm_b_config: Optional configuration for arm B
        split_strategy: Optional graph splitting strategy

    Returns:
        Experiment results
    """
    # Default configurations
    if arm_a_config is None or arm_b_config is None:
        arm_a_config, arm_b_config = get_baseline_vs_bridge_aware_configs()

    # Default split strategy
    if split_strategy is None:
        split_strategy = CommunityAwareSplit()

    # Initialize A/B test
    ab_test = Node2VecABTest(arm_a_config, arm_b_config, split_strategy)

    # Prepare graph
    experiment_graph = ab_test.prepare_experiment_graph(social_graph, semantic_positions)

    # Run experiment
    results = ab_test.run_experiment(experiment_graph, user_ids, split_ratio=0.5)

    # Print report
    print(ab_test.generate_report())

    return results

# ============================================================================
# Example Usage (for Jupyter Notebook)
# ============================================================================

if __name__ == "__main__":
    print("Node2Vec A/B Testing Framework")
    print("=" * 80)
    print("\nExample usage in Jupyter Notebook:")
    print("""
    # 1. Create or load your social graph
    import networkx as nx
    social_graph = nx.karate_club_graph()  # Example graph

    # 2. Prepare user IDs and semantic positions (optional)
    user_ids = [f"user_{i}" for i in social_graph.nodes()]
    semantic_positions = {uid: np.random.randn(32) for uid in user_ids}

    # 3. Run A/B experiment
    from node2vec_ab_testing import run_node2vec_ab_experiment

    results = run_node2vec_ab_experiment(
        social_graph,
        user_ids,
        semantic_positions
    )

    # 4. Or customize configurations
    from node2vec_ab_testing import Node2VecExperimentConfig, Node2VecABTest

    arm_a = Node2VecExperimentConfig(
        arm_id="low_dim",
        dimensions=64,
        use_bridge_weights=False
    )

    arm_b = Node2VecExperimentConfig(
        arm_id="high_dim_bridge",
        dimensions=256,
        use_bridge_weights=True
    )

    results = run_node2vec_ab_experiment(
        social_graph,
        user_ids,
        semantic_positions,
        arm_a,
        arm_b
    )
    """)